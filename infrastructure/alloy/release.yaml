---
# HelmRelease for Grafana Alloy
# Log collection agent - collects container logs via Kubernetes API and ships to Loki
# Uses K8s API instead of hostPath mounts (no privileged access needed)
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: alloy
  namespace: flux-system
spec:
  interval: 10m
  chart:
    spec:
      chart: alloy
      version: '>=0.9.0 <1.0.0'
      sourceRef:
        kind: HelmRepository
        name: grafana
        namespace: flux-system
      interval: 1h

  targetNamespace: monitoring
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    # DaemonSet on Raspberry Pis needs more time to roll out
    timeout: 15m
    remediation:
      retries: 3

  values:
    # ==================================================================
    # ALLOY CONFIGURATION
    # River config defining the log collection pipeline
    # Uses Kubernetes API to fetch logs (no hostPath needed!)
    # ==================================================================
    alloy:
      configMap:
        content: |
          // ============================================================
          // KUBERNETES LOG COLLECTION PIPELINE
          // Uses Kubernetes API to stream pod logs (no hostPath mount needed)
          // This approach works with any PodSecurity policy
          // ============================================================

          // Discover all pods in the cluster
          discovery.kubernetes "pods" {
            role = "pod"
          }

          // Relabel to extract useful labels for Loki
          discovery.relabel "pods" {
            targets = discovery.kubernetes.pods.targets

            // Keep only running pods
            rule {
              source_labels = ["__meta_kubernetes_pod_phase"]
              regex         = "Pending|Succeeded|Failed|Unknown"
              action        = "drop"
            }

            // Set the namespace label
            rule {
              source_labels = ["__meta_kubernetes_namespace"]
              target_label  = "namespace"
            }

            // Set the pod label
            rule {
              source_labels = ["__meta_kubernetes_pod_name"]
              target_label  = "pod"
            }

            // Set the container label
            rule {
              source_labels = ["__meta_kubernetes_pod_container_name"]
              target_label  = "container"
            }

            // Set the node label
            rule {
              source_labels = ["__meta_kubernetes_pod_node_name"]
              target_label  = "node"
            }

            // Set app label from common label patterns
            rule {
              source_labels = ["__meta_kubernetes_pod_label_app"]
              target_label  = "app"
            }
            rule {
              source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
              target_label  = "app"
            }
          }

          // Collect logs via Kubernetes API
          // This streams logs directly from the API server, no file access needed
          loki.source.kubernetes "pods" {
            targets    = discovery.relabel.pods.output
            forward_to = [loki.process.pods.receiver]
          }

          // Process logs before sending to Loki
          loki.process "pods" {
            forward_to = [loki.write.default.receiver]

            // Add static job label
            stage.static_labels {
              values = {
                job = "kubernetes-pods",
              }
            }
          }

          // Ship logs to Loki
          // Service name is "monitoring-loki" (helm release name prefix)
          loki.write "default" {
            endpoint {
              url = "http://monitoring-loki.monitoring.svc.cluster.local:3100/loki/api/v1/push"
            }
          }

      # No volume mounts needed - we use the Kubernetes API!
      mounts:
        varlog: false

      # Clustering ensures logs aren't duplicated across replicas
      clustering:
        enabled: true

    # ==================================================================
    # DEPLOYMENT CONFIGURATION
    # Using Deployment instead of DaemonSet since we're reading from API
    # ==================================================================
    controller:
      type: deployment
      replicas: 2

    # ==================================================================
    # RESOURCE LIMITS
    # Keep it light for Raspberry Pi
    # ==================================================================
    resources:
      limits:
        cpu: 200m
        memory: 256Mi
      requests:
        cpu: 50m
        memory: 128Mi
