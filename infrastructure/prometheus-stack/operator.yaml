---
# HelmRelease for kube-prometheus-stack
# This is the full monitoring stack including:
# - Prometheus Operator (manages Prometheus/Alertmanager/ServiceMonitor CRDs)
# - Prometheus (metrics collection and storage)
# - Grafana (visualization and dashboards)
# - Alertmanager (alert routing and notification)
# - Node Exporter (exports host-level metrics from each node)
# - Kube-State-Metrics (exports K8s object state metrics)
# - Pre-configured ServiceMonitors for K8s components (kubelet, apiserver, etc.)
#
# Everything configured with EPHEMERAL storage - data does not persist across pod restarts
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: flux-system
spec:
  interval: 10m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: '>=60.0.0 <61.0.0'  # Use latest 60.x (supports K8s 1.34)
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
      interval: 1h

  # Install into monitoring namespace (conventional for observability stack)
  targetNamespace: monitoring
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    remediation:
      retries: 3

  values:
    # ==================================================================
    # PROMETHEUS OPERATOR
    # The controller that manages Prometheus/Alertmanager instances
    # ==================================================================
    prometheusOperator:
      resources:
        limits:
          cpu: 200m
          memory: 256Mi
        requests:
          cpu: 100m
          memory: 128Mi

      # Config reloader sidecar watches for ConfigMap changes
      prometheusConfigReloader:
        resources:
          limits:
            cpu: 100m
            memory: 50Mi
          requests:
            cpu: 50m
            memory: 25Mi

    # ==================================================================
    # PROMETHEUS
    # The actual metrics collection and storage engine
    # ==================================================================
    prometheus:
      prometheusSpec:
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: local-path
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 16Gi
        retention: 7d

        # Resources for Prometheus pods
        resources:
          limits:
            cpu: 500m
            memory: 2Gi  # Needs RAM for in-memory storage + processing
          requests:
            cpu: 250m
            memory: 1Gi

        # Scrape interval: How often to collect metrics
        scrapeInterval: 30s
        evaluationInterval: 30s

    # ==================================================================
    # ALERTMANAGER
    # Routes and manages alerts (emails, Slack, PagerDuty, etc.)
    # ==================================================================
    alertmanager:
      alertmanagerSpec:
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: local-path
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 1Gi

        resources:
          limits:
            cpu: 100m
            memory: 128Mi
          requests:
            cpu: 50m
            memory: 64Mi

    # ==================================================================
    # GRAFANA
    # Visualization and dashboard interface
    # ==================================================================
    grafana:
      # Admin credentials - CHANGE THESE!
      adminPassword: "admin"  # TODO: Change this or use a Secret

      # EPHEMERAL STORAGE: Dashboards/datasources stored in tmpfs
      # You can provision dashboards via ConfigMaps to persist them in GitOps
      persistence:
        enabled: false  # No PVC, uses emptyDir by default

      resources:
        limits:
          cpu: 200m
          memory: 256Mi
        requests:
          cpu: 100m
          memory: 128Mi

      # Datasource auto-configured to point to Prometheus in same namespace
      # This is done automatically by the chart

    # ==================================================================
    # NODE EXPORTER
    # DaemonSet that runs on every node, exports host metrics
    # (CPU, memory, disk, network at the OS level)
    # ==================================================================
    nodeExporter:
      enabled: true

    # ==================================================================
    # KUBE-STATE-METRICS
    # Exports metrics about Kubernetes objects themselves
    # (Pod status, Deployment replicas, Node conditions, etc.)
    # ==================================================================
    kubeStateMetrics:
      enabled: true

    # ==================================================================
    # DEFAULT SERVICE MONITORS
    # Pre-configured scrapers for K8s components
    # ==================================================================
    # These are all enabled by default and create ServiceMonitors for:
    # - kubelet (node-level metrics)
    # - kube-apiserver
    # - kube-controller-manager
    # - kube-scheduler
    # - kube-proxy
    # - coreDNS
    #
    # You can explore these with: kubectl get servicemonitor -n monitoring
